---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.path = "tools/README-"
)
```


[![Build Status](https://api.travis-ci.org/kassambara/rstatix.png)](https://travis-ci.org/kassambara/rstatix)
[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/rstatix)](https://cran.r-project.org/package=rstatix)
[![CRAN Checks](https://cranchecks.info/badges/summary/rstatix)](https://cran.r-project.org/web/checks/check_results_rstatix.html)
[![Downloads](https://cranlogs.r-pkg.org/badges/rstatix)](https://cran.r-project.org/package=rstatix)
[![Total Downloads](https://cranlogs.r-pkg.org/badges/grand-total/rstatix?color=orange)](https://cranlogs.r-pkg.org/badges/grand-total/rstatix)


# rstatix

Provides a pipe-friendly framework to perform easily basic statistical tests in R. The output of each test is automatically transformed into a tidy data frame to facilitate visualization.
   
   
## Key functions
   
   
### Descriptive statistics
   
- `get_summary_stats()`: Compute summary statistics for one or multiple numeric variables. Can handle grouped data.
- `get_mode()`: Compute the mode of a vector, that is the most frequent values.
- `identify_outliers()`: Detect univariate outliers using boxplot methods. 
- `mahalanobis_distance()`: Compute Mahalanobis Distance and Flag Multivariate Outliers.
- `shapiro_test()` and `mshapiro_test()`: Univariate and multivariate Shapiro-Wilk normality test.
   
   
### Comparing means
     
- `t_test()`: perform one-sample, two-sample and pairwise t-tests
- `wilcox_test()`: perform one-sample, two-sample and pairwise Wilcoxon tests
- `anova_test()`: an easy-to-use wrapper around `car::Anova()` to perform different types of ANOVA tests, including **independent measures ANOVA**, **repeated measures ANOVA** and **mixed ANOVA**.
- `kruskal_test()`: perform kruskal-wallis rank sum test
- `tukey_hsd()`: performs tukey post-hoc tests. Can handle different inputs formats: aov, lm, formula.
   
### Facilitating ANOVA computation in R
   
- `factorial_design()`: build factorial design for easily computing ANOVA using the `car::Anova()` function. This might be very useful for repeated measures ANOVA, which is hard to set up with the `car` package.
- `anova_summary()`: Create beautiful summary tables of ANOVA test results obtained from either `car::Anova()` or `stats::aov()`. The results include ANOVA table, generalized effect size and some assumption checks, such as Mauchly's test for sphericity in the case of repeated measures ANOVA.
   
### Comparing variances
   
- `levene_test()`: Pipe-friendly framework to easily compute Levene's test for homogeneity of variance across groups. Handles grouped data.
- `box_m()`: Box's M-test for homogeneity of covariance matrices
   
   
### Effect Size
   
- `cohens_d()`: Compute cohen's d measure of effect size for t-tests.
- `eta_squared()` and `partial_eta_squared()`: Compute effect size for ANOVA.
   
### Correlation analysis
   
**Computing correlation**:  
   
- `cor_test()`: correlation test between two or more variables using Pearson, Spearman or Kendall methods.
- `cor_mat()`: compute correlation matrix with p-values. Returns a data frame containing the matrix of the correlation coefficients. The output has an attribute named "pvalue", which contains the matrix of the correlation test p-values.
- `cor_get_pval()`: extract a correlation matrix p-values from an object of class `cor_mat()`.
- `cor_pmat()`: compute the correlation matrix, but returns only the p-values of the correlation tests.
- `as_cor_mat()`: convert a `cor_test` object into a correlation matrix format.
    
**Reshaping correlation matrix**:  
  
- `cor_reorder()`: reorder correlation matrix, according to the coefficients, using the hierarchical clustering method.
- `cor_gather()`: takes a correlation matrix and collapses (or melt) it into long format data frame (paired list)
- `cor_spread()`: spread a long correlation data frame into wide format (correlation matrix).
  
  
**Subsetting correlation matrix**:

- `cor_select()`: subset a correlation matrix by selecting variables of interest.
- `pull_triangle()`, `pull_upper_triangle()`, `pull_lower_triangle()`: pull upper and lower triangular parts of a (correlation) matrix.
- `replace_triangle()`, `replace_upper_triangle()`, `replace_lower_triangle()`: replace upper and lower triangular parts of a (correlation) matrix.
   
   
**Visualizing correlation matrix**:
   
- `cor_as_symbols()`: replaces the correlation coefficients, in a matrix, by symbols according to the value.
- `cor_plot()`: visualize correlation matrix using base plot.
- `cor_mark_significant()`: add significance levels to a correlation matrix.
  
  
### Adjusting p-values and adding significance symbols
      
- `adjust_pvalue()`: add an adjusted p-values column to a data frame containing statistical test p-values
- `add_significance()`: add a column containing the p-value significance level
   
   
### Others
   
- `doo()`: alternative to dplyr::do for doing anything. Technically it uses `nest() + mutate() + map()` to apply arbitrary computation to a grouped data frame.
- `sample_n_by()`: sample n rows by group from a table
- `convert_as_factor(), set_ref_level(), reorder_levels()`: Provides pipe-friendly functions to convert simultaneously multiple variables into a factor variable.
- `make_clean_names()`: Pipe-friendly function to make syntactically valid column names (for input data frame) or names (for input vector).
- `cramer_v()`: Compute Cramer's V, which measures the strength of the association between categorical variables.
   
   
## Installation and loading
    
    
- Install the latest version from [GitHub](https://github.com/kassambara/rstatix) as follow: 
    
   
```{r, eval = FALSE}
# Install
if(!require(devtools)) install.packages("devtools")
devtools::install_github("kassambara/rstatix")
```
     
     
- Loading packages
   
```{r}
library(rstatix)  
library(ggpubr)  # For easy data-visualization
```
  
  
## Descriptive statistics
    
```{r}
# Summary statistics of some selected variables
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
iris %>% 
  get_summary_stats(Sepal.Length, Sepal.Width, type = "common")

# Whole data frame
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
iris %>% get_summary_stats(type = "common")


# Grouped data
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
iris %>%
  group_by(Species) %>% 
  get_summary_stats(Sepal.Length, type = "mean_sd")
```

     
## Comparing two means
   
To compare the means of two groups, you can use either the function `t_test()` (parametric) or `wilcox_test()` (non-parametric). In the following example the t-test will be illustrated.
   
### Data
   
   
Preparing the demo data set:
   
```{r}
df <- ToothGrowth
df$dose <- as.factor(df$dose)
head(df)
```

   
### Compare two independent groups
   
   
- Create a simple box plot with p-values:
   
```{r unpaired-two-sample-t-test, fig.width=3.5, fig.height=4}
# T-test
stat.test <- df %>% 
  t_test(len ~ supp, paired = FALSE) 
stat.test

# Create a box plot
p <- ggboxplot(
  df, x = "supp", y = "len", 
  color = "supp", palette = "jco", ylim = c(0,40)
  )
# Add the p-value manually
p + stat_pvalue_manual(stat.test, label = "p", y.position = 35)
```
    
    
- Customize labels using [glue expression](https://github.com/tidyverse/glue): 

  
```{r custoize-p-value-labels, fig.width=3.5, fig.height=4}
p +stat_pvalue_manual(stat.test, label = "T-test, p = {p}", 
                      y.position = 36)
```
    
    

- Grouped data: compare supp levels after grouping the data by "dose"
   
```{r grouped-two-sample-t-test, fig.width=6, fig.height=4}
# Statistical test
stat.test <- df %>%
  group_by(dose) %>%
  t_test(len ~ supp) %>%
  adjust_pvalue() %>%
  add_significance("p.adj")
stat.test

# Visualization
ggboxplot(
  df, x = "supp", y = "len",
  color = "supp", palette = "jco", facet.by = "dose",
  ylim = c(0, 40)
  ) +
  stat_pvalue_manual(stat.test, label = "p.adj", y.position = 35)
```
   
   
### Compare paired samples
    
    
```{r paired-t-test, fig.width=3.5, fig.height=4}
# T-test
stat.test <- df %>% 
  t_test(len ~ supp, paired = TRUE) 
stat.test

# Box plot
p <- ggpaired(
  df, x = "supp", y = "len", color = "supp", palette = "jco", 
  line.color = "gray", line.size = 0.4, ylim = c(0, 40)
  )
p + stat_pvalue_manual(stat.test, label = "p", y.position = 36)
```
    
    
   
### Multiple pairwise comparisons
   
   
- Pairwise comparisons: if the grouping variable contains more than two categories, a pairwise comparison is automatically performed.
   
   
```{r pairwise-comparisons, fig.width=3.5, fig.height=3}
# Pairwise t-test
pairwise.test <- df %>% t_test(len ~ dose)
pairwise.test
# Box plot
ggboxplot(df, x = "dose", y = "len")+
  stat_pvalue_manual(
    pairwise.test, label = "p.adj", 
    y.position = c(29, 35, 39)
    )
```
    
    
    
- Multiple pairwise comparisons against reference group: each level is compared to the ref group
    
    
```{r comaprison-against-reference-group, fig.width=3.5, fig.height=3}
# Comparison against reference group
#::::::::::::::::::::::::::::::::::::::::
# T-test: each level is compared to the ref group
stat.test <- df %>% t_test(len ~ dose, ref.group = "0.5")
stat.test
# Box plot
ggboxplot(df, x = "dose", y = "len", ylim = c(0, 40)) +
  stat_pvalue_manual(
    stat.test, label = "p.adj.signif", 
    y.position = c(29, 35)
    )
# Remove bracket
ggboxplot(df, x = "dose", y = "len", ylim = c(0, 40)) +
  stat_pvalue_manual(
    stat.test, label = "p.adj.signif", 
    y.position = c(29, 35),
    remove.bracket = TRUE
    )
```
   
   
- Multiple pairwise comparisons against all (base-mean): Comparison of each group against base-mean.
   
   
```{r comparison-against-base-mean, fig.width=3.5, fig.height=3}
# T-test
stat.test <- df %>% t_test(len ~ dose, ref.group = "all")
stat.test
# Box plot with horizontal mean line
ggboxplot(df, x = "dose", y = "len") +
  stat_pvalue_manual(
    stat.test, label = "p.adj.signif", 
    y.position = 35,
    remove.bracket = TRUE
    ) +
  geom_hline(yintercept = mean(df$len), linetype = 2)
```
    
    
## ANOVA test
    
```{r}
# One-way ANOVA test
#:::::::::::::::::::::::::::::::::::::::::
df %>% anova_test(len ~ dose)

# Two-way ANOVA test
#:::::::::::::::::::::::::::::::::::::::::
df %>% anova_test(len ~ supp*dose)

# Two-way repeated measures ANOVA
#:::::::::::::::::::::::::::::::::::::::::
df$id <- rep(1:10, 6) # Add individuals id
# Use formula
# df %>% anova_test(len ~ supp*dose + Error(id/(supp*dose)))
# or use character vector
df %>% anova_test(dv = len, wid = id, within = c(supp, dose))

# Use model as arguments
#:::::::::::::::::::::::::::::::::::::::::
.my.model <- lm(yield ~ block + N*P*K, npk)
anova_test(.my.model)
```
   
   
## Correlation tests
   
```{r}
# Data preparation
mydata <- mtcars %>% 
  select(mpg, disp, hp, drat, wt, qsec)
head(mydata, 3)

# Correlation test between two variables
mydata %>% cor_test(wt, mpg, method = "pearson")

# Correlation of one variable against all
mydata %>% cor_test(mpg, method = "pearson")

# Pairwise correlation test between all variables
mydata %>% cor_test(method = "pearson")
```
   
   
## Correlation matrix
   
```{r, fig.width=4, fig.height=4}
# Compute correlation matrix
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
cor.mat <- mydata %>% cor_mat()
cor.mat

# Show the significance levels
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
cor.mat %>% cor_get_pval()

# Replacing correlation coefficients by symbols
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
cor.mat %>%
  cor_as_symbols() %>%
  pull_lower_triangle()

# Mark significant correlations
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
cor.mat %>%
  cor_mark_significant()


# Draw correlogram using R base plot
#::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
cor.mat %>%
  cor_reorder() %>%
  pull_lower_triangle() %>% 
  cor_plot()
```

    
## Related articles
   
   
- [Add P-values and Significance Levels to ggplots](http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/)
